Работа с памятью в Linux
Линейное пространство адресов процесса разбивается на несколько частей: 3 Гб
под пользователя и 1 Гб под ядро. В первых 3 Гб в адресах до 0xС0000000
процесс работает в режиме обычного пользователя, а адреса выше используются
в режиме суперюзера.

Надо заметить, что не в каждой системе поддерживается одинаковый доступ к
памяти(UMA), потому в Linux поддерживается модель NUMA. В этой модели
физическая паять системы разделяется на несколько узлов. Каждый узел
описывается структурой pg_data_t (include/linux/mmzone.h). Все дескрипторы
узлов хранятся в глобальном массиве mem_map, который располагается в
                     pg_data_t
                         |
     ________________node_zones_______________
    /                    |                    \
ZONE_DMA            ZONE_NORMAL          ZONE_HIGHMEM
    |                    |                     |
zone_mem_map        zone_mem_map           zone_mem_map

Зоны каждого узла физической памяти:
    ZONE_HIGHMEM    - содержит страничные кадры выше 896 Мб
    ZONE_NORMAL     - from 16Mb to 896 Mb
    ZONE_DMA        - first 16 Mb

К NORMAL и DMA ядро может обращаться напрямую через отображение в 4 Гб
линейного адресного пространства. Зато HIGHMEM зона содержит кадры, к
которым ядро так просто не обратится. Так как HIGHMEM содержит кадры,
линейные адреса, которых не существуют, то выделять страничные кадры можно
только с помощью функции alloc_page(), которая возвращает указатель(линейный
адрес) не на первый страничный кадр, а на первый страничный дескриптор,
описывающий этот кадр. Все дескрипторы физических кадров находятся в NORMAL,
потому для них всегда существует линейный адрес.
Для отображения верхних адресов в линейное адресное пространство используются верхние 128 МБ NORMAL адресов(временное отображение). Есть несколько техник для отображения:
    * постоянное,
    * временное отображения,
    * работа с несмежными областями памяти.

Каждый физический кадр описывается фундаментальной структурой данных
struct page(/include/linux/mm_types.h). Структура используется, чтобы
отслеживать состояние страничного кадра: выделен или нет, кому принадлежит,
что на нём хранится. Структура организована в блоки двойных слов для
выполнения над ними атомарных операций работающих с двойными словами.
Опишем важные поля структуры:
    * atomic_t _refcount(до 2016 года _count https://patchwork.kernel.org/
patch/8678251/) - количество ссылок на структуру page. Из
init_free_pfn_range следует, что если _refcount равен 0, то страничный кадр
свободен, если >0, то кем-то или чем-то занят.
    * unsigned long flags - содержит флаги, описывающие состояние страничного
кадра. Флаги описаны в  include/linux/page-flags.h

Самый первый доступный ядру алокатор памяти - bootmem(/mm/bootmem.c).
bootmem алокатор используется только при загрузке ядра для начального
выделения физической памяти до того, как подсистема управления памятью станет
доступной.
bootmem работает очень прямолинейно по алгоритму первый подходящий - ищет
первый свободный кусок(страницу) физической памяти и выдаёт. Для
представления физической памяти использует bitmap, если 1, то страница
занята, если 0, то свободна. Для выделения памяти меньше страницы он
записывает PFN последней такой алокации, и следующая маленькая локация будет, если возможно, располагаться на той же физической странице.
Алокатор с алгоритмом первый наиболее подходящий, не сильно страдает от
фрагментации, но из-за использования bitmap крайне медленный.
/include/linux/bootmem.h
/*
 * node_bootmem_map is a map pointer - the bits represent all physical
 * memory pages (including holes) on the node.
 */
typedef struct bootmem_data {
    unsigned long       node_min_pfn;
    unsigned long       node_low_pfn;
    void                *node_bootmem_map;
    unsigned long       last_end_off;
    unsigned long       hint_idx;
    struct list_head    list;
} bootmem_data_t;

После начальной загрузки и инициализации памяти ядру становятся доступны
другие аллокаторы:
---------------
|   kmalloc   |
------------------------
|   kmemcache | vmalloc|
------------------------
|         buddy        |
------------------------
Buddy - аллокатор смежных страничных кадров, а не линейных страниц, так как
для некоторых задач, таких как DMA нужны именно смежные физические страницы,
потому что DMA-устройства работают с памятью напрямую. Ещё одной причиной
такого подхода является то, что это позволяет не трогать таблицы страниц
ядра, что ускоряет работу с памятью.
Проблема аллокаторов смежных страниц - внешняя фрагментация, потому в buddy
аллокаторе в Linux применяется стандартный подход - разбиение всех доступных
страничных кадров на списки по степени двойки: 1, 2, 4, 8, 16, …, 1024.
1024*4096 = 4МВ. Физический адрес первого страничного кадра в блоке кратен
размеру группы.
Алгоритм работы: хотим выделить 256 кадров. Аллокатор проверит в списке 256,
если нет, заглянет в 512, если есть возьмёт 256 кадров, а оставшиеся
поместит в список 256. Если и в 512 нет, то проверяет в 1024, если есть, то
возвращает 256 кадров запросившему, а оставшиеся 768 разобьёт по двум
спискам 512 и 256, если и в 1024 нет, то сигналит об ошибке.
У системы buddy есть глобальный объект, хранящий дескрипторы всех доступных
кадров, а на каждом отдельном процессоре есть свои локальные списки
доступных кадров, если в локальных списках закончилась память, то он
подтягивает из глобального и наоборот возвращает если в локальных они
свободны. У каждой зоны свой собственный buddy аллокатор.
Для работы с buddy аллокатором необходимо использовать функции
alloc_page/__rmqueue()(mm/page_alloc.c) - выделение, __free_pages()-
освобождение. При работе с этими функциями необходимо отключать прерывания и
брать спин блокировку zone->lock.
Плюсы buddy:
    Быстрее bootmem(не использует bitmap).
    Можно выделять несколько страничных кадров подряд.
Минусы buddy:
    Нельзя выделить меньше страничного кадра, всегда выделяет >= PAGESIZE.
    Выделяет только идущие по очереди в физической памяти, что всё равно приводит к фрагментации.

У работы со смежными физическими областями есть свои плюсы в виде быстрой
работы с памятью, однако и минусы в виде внешней фрагментации. В Linux есть
возможность работать с несмежными областями физической памяти, к которым
можно обращаться через смежные области линейного пространства. Начало
области линейного пространства, где отображаются несмежные области
физического, можно получить из макроса VMALLOC_START, конец - VMALLOC_END.
Каждая несмежная область памяти описывается структурой(include/linux/
vmalloc.h)
struct vm_struct {
    struct vm_struct    *next;  // <- список
    void                *addr;  // линейный адрес первой ячейки
    unsigned long       size;   // size + 4096(окно безопасности между несмежными областями)
    unsigned long       flags;  // тип памяти, отображаемой несметной области
    struct page         **pages;
    unsigned int        nr_pages;
    phys_addr_t         phys_addr;
    const void          *caller;
};
Выделение страниц производится функцией void *vmalloc(unsigned long size)
(mm/vmalloc.c). size - размер запрашиваемой области. Выделяет память кратно
странице, потому первым делом округляет size до кратного странице размера.
Он выдаёт последовательные страницы, но уже в виртуальном адресном
пространстве. vmalloc берёт физические страницы у buddy по страничному кадру.
Освобождать память можно с помощью vfree().
Минус заключается в том, что наступает фрагментация, но уже в виртуальном
памяти, плюс появляется необходимость обращаться в таблицы страниц, что
долго. Потому vmalloc редко вызывают. Его применяют для модулей, буферы ввода
/вывода, сетевого экрана,отображение верхней памяти.

Очевидно, что для работы с маленькими областями памяти произвольной длины не
buddy, не vmalloc не подходят, из-за их расточительности. Потому в Linux
есть ещё одна система памяти - kmemcache, которая позволяет выделять память
под небольшие объекты в пределах страничного кадра. Однако тут надо быть
осторожнее, так как может возникнуть проблема внутренней фрагментации.
Вообще говоря под kmemcache скрывается аде целых 3 системы: SLAB/SLUB/SLOB.
Суть этих систем достаточно похожа, но имеются и существенные отличия:
SLOB - для встраиваемых подсистем, отсюда следует то, что он использует
минимум памяти и показывает низкую производительность, так же страдает от
внутренней фрагментации.
SLAB - был введён в солярисе и изначально был только он, но системы
становились большими и SLAB стал себя плохо показывать в системах с большим
количеством процессоров.
SLUB - эволюция SLAB - быстрее, выше, сильнее.

Сначала опишем интерфейс SLAB.
Slab базируется на нескольких наблюдениях. Во-первых, ядро часто запрашивает
и возвращает области памяти одного и того же размера для различных структур,
потому для ускорения можно не освобождать, а оставлять их в кеше для себя, а
потом переиспользовать, что сэкономит время. Лучше как можно реже обращаться
к buddy, так как каждое обращение к нему загрязняет аппаратный кэш. Так же
можно создать объекты размером не кратным двойки, если к ним происходит
частое обращение, что ещё может улучшить работу аппаратного кэша.
Slab группирует объекты в кэш. Каждый кэш - хранилище объектов одного типа(
размера). Кеш имеет несколько slab-списков: с полностью свободными
объектами, частично свободными  и полностью занятыми. Кэш работает с
гранулярностью 1-2-4 страницы.
kmem_cache       slab - список
________
|      |——————> | | -  | | - | |  - полностью свободны
|      |
|      |
|      |——————> | | -  | | - | |  - частично свободны
|      |
|      |——————> | | -  | | - | |  - полностью заняты
|      |
(include/linux/slub_def.h)

Для того чтобы пользоваться struct kmem_cache надо получить хэндл через функцию:
struct kmem_cache *kmem_cache_create(size);
size - фикцисрованный размер, который мы потом хотим получать.
После можно выделить память с помощью:
void kmem_cache_alloc(kc, flags);
И освобождать:
void kmem_cache_free(kc);
Уничтожить кэш можно с помощью:
kmem_cache_destroy()
Всю информацию по SLAB можно получить в /proc/slabinfo.

Под SLAB тоже нужно было выделять память, дескриптор описывающий SLAB мог лежать:
У другого kmem_cache - off-slab.
Дескриптор slab может лежать в голове страницы, которую выдаёт buddy - on-slab.

Но buddy выдавал нам страницу и struct page, который по размеру совпадал со
slab -> struct page можно забрать у системы и использовать его под slab.
Потому появился slub.
Минус SLAB allocator - выделяет объекты константного размера, хотя нам не
всегда известен размер объекта под который нужно выделить память.

Более высокого уровня аллокатор kmalloc/kfree(include/linux/slab.h). Он
обращается к необходимому kmem_cache, получая его через статическую функцию
kmalloc_index(size). В статической функции, если размер будет известен на
этапе компиляции, то вызов функции будет компилятором заменён на итоговый
индекс.:
static __always_inline int kmalloc_index(size_t size)
{
…
if (KMALLOC_MIN_SIZE <= 32 && size > 64 && size <= 96)
        return 1;
    if (KMALLOC_MIN_SIZE <= 64 && size > 128 && size <= 192)
        return 2;
    if (size <=          8) return 3;
…
}
* 0 = zero alloc
* 1 =  65 .. 96 bytes
* 2 = 129 .. 192 bytes
* n = 2^(n-1)+1 .. 2^n
Кэши размером 0/ 8/ 16/ 32/ 64/ 96/ 128/ 192 /256 …/2^26. 96 и 192 -
эвристически вычисленные часто запрашиваемые значения.

Все аллокаторы работаю с группой флагов gfp_flags(uinclude/linux/gfp.h) -
get free page flags. Изначально они появились в buddy потом просочись на уровни повыше.

Типы флагов:
1. Откуда выделять: __GFP_DMA, __GFP_HIGHMEM, __GFP_DMA32. По умолчанию
система старается выделять память в ZONE_NORMAL.
2. Поведение при нехватке памяти - контекст, в котором мы работаем по сути.
Если памяти нет, то её нужно найти, например:
    в дисковом кэше - требуется брать мютекс;
    ядерном кэше  - требуется брать мютекс;
    освободить грязный дисковый кэш  - требуется брать мютекс и обращаться к файловой системе и блокам;
    swap  требуется брать мютекс и обращаться к блокам;
    kill кого-нибудь;
Пример,  __GFP_ATOMIC - ничего нельзя делать и buddy вернёт NULL.
__GFP_NOFS - используются кэшами и буферами, чтобы быть уверенными, что их
рекурсивно не позовут. __GFP_NOIO.
3. Всё остальное - __GFP_ZERO - память которую выдаст аллокатор должен быть
забит нулями. __GFP_TEMPORARY - мне нужно выделить страницу подержу её
недолго и верну. (пути) GFP_NORETRY GFP_NOFAIL
